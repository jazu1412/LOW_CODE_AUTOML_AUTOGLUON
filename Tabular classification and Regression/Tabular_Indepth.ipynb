{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96fa33c67ec6436997863170bdf92890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_813692f4c51c41a8b84ac941e6bef731",
              "IPY_MODEL_d7fffc9e975040c4aa3537770ecc3e5f",
              "IPY_MODEL_6b1fc6a37413421db4c9152a1fcb3019"
            ],
            "layout": "IPY_MODEL_95f60a4d8c0442a185083b0bbdb23ef2"
          }
        },
        "813692f4c51c41a8b84ac941e6bef731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29123f3656184c1a958761344762d55d",
            "placeholder": "​",
            "style": "IPY_MODEL_a8743ec373b742588bab0fe913b72ebc",
            "value": "100%"
          }
        },
        "d7fffc9e975040c4aa3537770ecc3e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2038d9c30b11418ca1db32ca038effed",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ca1bc128e4640a8a56ab7b602a8573f",
            "value": 5
          }
        },
        "6b1fc6a37413421db4c9152a1fcb3019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f7d91afc438441d91ae621658fd8eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_08d15106143c4c88a5d96adceb08248a",
            "value": " 5/5 [00:06&lt;00:00,  1.05it/s]"
          }
        },
        "95f60a4d8c0442a185083b0bbdb23ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29123f3656184c1a958761344762d55d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8743ec373b742588bab0fe913b72ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2038d9c30b11418ca1db32ca038effed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca1bc128e4640a8a56ab7b602a8573f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f7d91afc438441d91ae621658fd8eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d15106143c4c88a5d96adceb08248a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazu1412/LOW_CODE_AUTOML_AUTOGLUON/blob/master/Tabular%20classification%20and%20Regression/Tabular_Indepth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo860orAz_Vo",
        "outputId": "6e368fe9-7150-4cfe-c320-8a84921c547d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon.tabular[all]\n",
            "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.26.4)\n",
            "Collecting scipy<1.13,>=1.5.4 (from autogluon.tabular[all])\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.3.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (3.3)\n",
            "Collecting autogluon.core==1.1.1 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.features==1.1.1 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting xgboost<2.1,>=1.6 (from autogluon.tabular[all])\n",
            "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (2.7.17)\n",
            "Collecting torch<2.4,>=2.2 (from autogluon.tabular[all])\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting lightgbm<4.4,>=3.3 (from autogluon.tabular[all])\n",
            "  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all])\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular[all]) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular[all]) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular[all]) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.tabular[all])\n",
            "  Downloading boto3-1.35.19-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.tabular[all])\n",
            "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.2.7)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular[all]) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular[all]) (71.0.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]) (1.16.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.7.5)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.19.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (9.4.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.7.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=2.2->autogluon.tabular[all]) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=2.2->autogluon.tabular[all]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=2.2->autogluon.tabular[all]) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=2.2->autogluon.tabular[all]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=2.2->autogluon.tabular[all]) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.19 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular[all])\n",
            "  Downloading botocore-1.35.19-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular[all])\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.10.9.7)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (8.1.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.4.1)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (3.10.5)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (2.9.1)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.20.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (7.0.4)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.64.1)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (14.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.12.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular[all]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular[all]) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular[all]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular[all]) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.11 (from fastai<2.8,>=2.3.1->autogluon.tabular[all])\n",
            "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.4,>=2.2->autogluon.tabular[all]) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular[all]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular[all]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular[all]) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]) (9.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.4,>=2.2->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (2.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (24.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (4.0.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (2.23.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (13.8.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (4.3.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.19.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.20.0)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (2.19.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.65.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (1.24.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (2.27.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.16.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1; extra == \"all\"->autogluon.tabular[all]) (0.6.1)\n",
            "Downloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.19-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.19-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Installing collected packages: py-spy, opencensus-context, distlib, colorful, virtualenv, triton, tensorboardX, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, xgboost, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lightgbm, botocore, s3transfer, nvidia-cusolver-cu12, catboost, torch, ray, opencensus, boto3, aiohttp-cors, torchvision, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.22.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.22.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.22.3\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.1\n",
            "    Uninstalling xgboost-2.1.1:\n",
            "      Successfully uninstalled xgboost-2.1.1\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.4.0\n",
            "    Uninstalling lightgbm-4.4.0:\n",
            "      Successfully uninstalled lightgbm-4.4.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0+cu121\n",
            "    Uninstalling torch-2.4.0+cu121:\n",
            "      Successfully uninstalled torch-2.4.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.19.0+cu121\n",
            "    Uninstalling torchvision-0.19.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.19.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\n",
            "torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-cors-0.7.0 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.tabular-1.1.1 boto3-1.35.19 botocore-1.35.19 catboost-1.2.7 colorful-0.5.6 distlib-0.3.8 jmespath-1.0.1 lightgbm-4.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 opencensus-0.11.4 opencensus-context-0.1.3 py-spy-0.3.14 ray-2.10.0 s3transfer-0.10.2 scipy-1.12.0 tensorboardX-2.6.2.2 torch-2.3.1 torchvision-0.18.1 triton-2.3.1 virtualenv-20.26.4 xgboost-2.0.3\n",
            "       age workclass  fnlwgt      education  education-num  \\\n",
            "6118    51   Private   39264   Some-college             10   \n",
            "23204   58   Private   51662           10th              6   \n",
            "29590   40   Private  326310   Some-college             10   \n",
            "18116   37   Private  222450        HS-grad              9   \n",
            "33964   62   Private  109190      Bachelors             13   \n",
            "\n",
            "            marital-status        occupation    relationship    race      sex  \\\n",
            "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
            "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
            "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
            "18116        Never-married             Sales   Not-in-family   White     Male   \n",
            "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
            "\n",
            "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
            "6118              0             0              40   United-States    >50K  \n",
            "23204             0             0               8   United-States   <=50K  \n",
            "29590             0             0              44   United-States   <=50K  \n",
            "18116             0          2339              40     El-Salvador   <=50K  \n",
            "33964         15024             0              40   United-States    >50K  \n",
            "Summary of occupation column: \n",
            " count              1000\n",
            "unique               15\n",
            "top        Craft-repair\n",
            "freq                142\n",
            "Name: occupation, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# AutoGluon Tabular - In-Depth Examples\n",
        "\n",
        "# Setup and Data Loading\n",
        "# We're preparing our tools and data to predict people's occupations based on their characteristics.\n",
        "# This is like getting ready to solve a puzzle by organizing all the pieces and understanding what picture we're trying to create.\n",
        "\n",
        "!pip install autogluon.tabular[all]\n",
        "\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "import numpy as np\n",
        "\n",
        "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
        "subsample_size = 1000\n",
        "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
        "print(train_data.head())\n",
        "\n",
        "label = 'occupation'\n",
        "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n",
        "\n",
        "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
        "y_test = test_data[label]\n",
        "test_data_nolabel = test_data.drop(columns=[label])\n",
        "\n",
        "metric = 'accuracy'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameter Tuning\n",
        "# We're fine-tuning our prediction models to make them work better for our specific occupation prediction task.\n",
        "# This is like adjusting the settings on a camera to get the clearest picture possible in different lighting conditions.\n",
        "\n",
        "from autogluon.common import space\n",
        "\n",
        "nn_options = {\n",
        "    'num_epochs': 10,\n",
        "    'learning_rate': space.Real(1e-4, 1e-2, default=5e-4, log=True),\n",
        "    'activation': space.Categorical('relu', 'softrelu', 'tanh'),\n",
        "    'dropout_prob': space.Real(0.0, 0.5, default=0.1),\n",
        "}\n",
        "\n",
        "gbm_options = {\n",
        "    'num_boost_round': 100,\n",
        "    'num_leaves': space.Int(lower=26, upper=66, default=36),\n",
        "}\n",
        "\n",
        "hyperparameters = {\n",
        "    'GBM': gbm_options,\n",
        "    'NN_TORCH': nn_options,\n",
        "}\n",
        "\n",
        "time_limit = 2*60\n",
        "num_trials = 5\n",
        "search_strategy = 'auto'\n",
        "\n",
        "hyperparameter_tune_kwargs = {\n",
        "    'num_trials': num_trials,\n",
        "    'scheduler' : 'local',\n",
        "    'searcher': search_strategy,\n",
        "}\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_data,\n",
        "    time_limit=time_limit,\n",
        "    hyperparameters=hyperparameters,\n",
        "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "96fa33c67ec6436997863170bdf92890",
            "813692f4c51c41a8b84ac941e6bef731",
            "d7fffc9e975040c4aa3537770ecc3e5f",
            "6b1fc6a37413421db4c9152a1fcb3019",
            "95f60a4d8c0442a185083b0bbdb23ef2",
            "29123f3656184c1a958761344762d55d",
            "a8743ec373b742588bab0fe913b72ebc",
            "2038d9c30b11418ca1db32ca038effed",
            "7ca1bc128e4640a8a56ab7b602a8573f",
            "0f7d91afc438441d91ae621658fd8eeb",
            "08d15106143c4c88a5d96adceb08248a"
          ]
        },
        "id": "zljoPH0E8dE6",
        "outputId": "ea39cc55-3cea-4764-8896-e00a02eca73d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240916_044017\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.13 GB / 12.67 GB (87.8%)\n",
            "Disk Space Avail:   70.89 GB / 112.64 GB (62.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
            "Beginning AutoGluon training ... Time limit = 120s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240916_044017\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       occupation\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 13 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
            "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.996\n",
            "Train Data Class Count: 13\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11393.93 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.23s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 796, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'GBM': {'num_boost_round': 100, 'num_leaves': Int: lower=26, upper=66},\n",
            "\t'NN_TORCH': {'num_epochs': 10, 'learning_rate': Real: lower=0.0001, upper=0.01, 'activation': Categorical['relu', 'softrelu', 'tanh'], 'dropout_prob': Real: lower=0.0, upper=0.5},\n",
            "}\n",
            "Fitting 2 L1 models ...\n",
            "Hyperparameter tuning model: LightGBM ... Tuning model for up to 53.89s of the 119.76s of remaining time.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96fa33c67ec6436997863170bdf92890"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "Fitted model: LightGBM/T1 ...\n",
            "\t0.37\t = Validation score   (accuracy)\n",
            "\t3.66s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitted model: LightGBM/T2 ...\n",
            "\t0.355\t = Validation score   (accuracy)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitted model: LightGBM/T3 ...\n",
            "\t0.375\t = Validation score   (accuracy)\n",
            "\t0.48s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitted model: LightGBM/T4 ...\n",
            "\t0.36\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitted model: LightGBM/T5 ...\n",
            "\t0.375\t = Validation score   (accuracy)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 53.89s of the 113.14s of remaining time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------+\n",
            "| Configuration for experiment     NeuralNetTorch   |\n",
            "+---------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator  |\n",
            "| Scheduler                        FIFOScheduler    |\n",
            "| Number of trials                 5                |\n",
            "+---------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/AutogluonModels/ag-20240916_044017/models/NeuralNetTorch\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitted model: NeuralNetTorch/dde0c39d ...\n",
            "\t0.355\t = Validation score   (accuracy)\n",
            "\t9.59s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/755823a3 ...\n",
            "\t0.345\t = Validation score   (accuracy)\n",
            "\t7.57s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/86fb2f39 ...\n",
            "\t0.33\t = Validation score   (accuracy)\n",
            "\t6.2s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/ede6a76f ...\n",
            "\t0.35\t = Validation score   (accuracy)\n",
            "\t9.52s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitted model: NeuralNetTorch/4cdd890c ...\n",
            "\t0.325\t = Validation score   (accuracy)\n",
            "\t3.86s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.77s of the 63.93s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch/ede6a76f': 0.333, 'LightGBM/T1': 0.25, 'LightGBM/T3': 0.25, 'NeuralNetTorch/4cdd890c': 0.167}\n",
            "\t0.405\t = Validation score   (accuracy)\n",
            "\t0.19s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 56.32s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3864.6 rows/s (200 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240916_044017\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predictions and Evaluation\n",
        "# Now we're using our fine-tuned model to predict occupations and checking how accurate it is.\n",
        "# This is like testing our camera settings by taking pictures and seeing how clear they are.\n",
        "\n",
        "y_pred = predictor.predict(test_data_nolabel)\n",
        "print(\"Predictions: \", list(y_pred)[:5])\n",
        "perf = predictor.evaluate(test_data, auxiliary_metrics=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6IzT2IY8kkp",
        "outputId": "7b532eee-df7a-4787-db25-8ebdcf0fb750"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:  [' Other-service', ' Craft-repair', ' Exec-managerial', ' Sales', ' Other-service']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit Summary\n",
        "# We're getting an overview of how well our model-tuning process went and what we learned from it.\n",
        "# This is like reviewing the photos we've taken to understand what settings worked best for different situations.\n",
        "\n",
        "results = predictor.fit_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKZw9T8Q8n69",
        "outputId": "4ada3942-5a49-4ece-b309-935bd5aa360f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                      model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0       WeightedEnsemble_L2      0.405    accuracy       0.051752  17.701887                0.001601           0.187042            2       True         11\n",
            "1               LightGBM/T3      0.375    accuracy       0.006179   0.481398                0.006179           0.481398            1       True          3\n",
            "2               LightGBM/T5      0.375    accuracy       0.010228   0.605839                0.010228           0.605839            1       True          5\n",
            "3               LightGBM/T1      0.370    accuracy       0.004826   3.657784                0.004826           3.657784            1       True          1\n",
            "4               LightGBM/T4      0.360    accuracy       0.016985   0.664174                0.016985           0.664174            1       True          4\n",
            "5               LightGBM/T2      0.355    accuracy       0.007997   0.643225                0.007997           0.643225            1       True          2\n",
            "6   NeuralNetTorch/dde0c39d      0.355    accuracy       0.053336   9.587120                0.053336           9.587120            1       True          6\n",
            "7   NeuralNetTorch/ede6a76f      0.350    accuracy       0.024500   9.517067                0.024500           9.517067            1       True          9\n",
            "8   NeuralNetTorch/755823a3      0.345    accuracy       0.041605   7.566391                0.041605           7.566391            1       True          7\n",
            "9   NeuralNetTorch/86fb2f39      0.330    accuracy       0.037497   6.196521                0.037497           6.196521            1       True          8\n",
            "10  NeuralNetTorch/4cdd890c      0.325    accuracy       0.014646   3.858595                0.014646           3.858595            1       True         10\n",
            "Number of models trained: 11\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'TabularNeuralNetTorchModel', 'LGBModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
            "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "('int', ['bool']) : 2 | ['sex', 'class']\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20240916_044017SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model Ensembling\n",
        "# We're combining multiple prediction models to create a \"super model\" that's more accurate than any single model.\n",
        "# This is like asking a group of experts for their opinion instead of relying on just one person's judgment.\n",
        "\n",
        "label = 'class'\n",
        "test_data_nolabel = test_data.drop(columns=[label])\n",
        "y_test = test_data[label]\n",
        "save_path = 'agModels-predictClass'\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n",
        "    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1,\n",
        "    hyperparameters = {'NN_TORCH': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},\n",
        ")\n",
        "\n",
        "predictor = TabularPredictor(label=label, eval_metric='f1', path=save_path).fit(\n",
        "    train_data, auto_stack=True,\n",
        "    time_limit=30, hyperparameters={'FASTAI': {'num_epochs': 10}, 'GBM': {'num_boost_round': 200}}\n",
        ")\n",
        "predictor.leaderboard(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DQY2bczX8qQv",
        "outputId": "4840d830-1e95-4b9e-f407-18e6619587e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240916_044147\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.48 GB / 12.67 GB (82.7%)\n",
            "Disk Space Avail:   70.87 GB / 112.64 GB (62.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240916_044147\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10732.60 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {'num_epochs': 2},\n",
            "\t'GBM': {'num_boost_round': 20},\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 2 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t0.823\t = Validation score   (accuracy)\n",
            "\t13.61s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t0.744\t = Validation score   (accuracy)\n",
            "\t22.57s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.823\t = Validation score   (accuracy)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 2 L2 models ...\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t0.828\t = Validation score   (accuracy)\n",
            "\t13.8s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
            "\t0.748\t = Validation score   (accuracy)\n",
            "\t23.34s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.833, 'LightGBM_BAG_L1': 0.167}\n",
            "\t0.829\t = Validation score   (accuracy)\n",
            "\t0.07s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 88.16s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 447.4 rows/s (200 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240916_044147\")\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.15 GB / 12.67 GB (80.0%)\n",
            "Disk Space Avail:   70.86 GB / 112.64 GB (62.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=5\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"agModels-predictClass\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10389.04 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.3s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'FASTAI': {'num_epochs': 10},\n",
            "\t'GBM': {'num_boost_round': 200},\n",
            "}\n",
            "Fitting 2 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 29.67s of the 29.67s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t0.6856\t = Validation score   (f1)\n",
            "\t28.07s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Completed 1/5 k-fold bagging repeats ...\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.67s of the -2.19s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.6856\t = Validation score   (f1)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 32.25s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1571.6 rows/s (125 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
              "0      LightGBM_BAG_L1    0.629437    0.68559          f1        0.646967   \n",
              "1  WeightedEnsemble_L2    0.629437    0.68559          f1        0.650326   \n",
              "\n",
              "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
              "0       0.079037  28.068850                 0.646967                0.079037   \n",
              "1       0.083040  28.077852                 0.003359                0.004002   \n",
              "\n",
              "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
              "0          28.068850            1       True          1  \n",
              "1           0.009001            2       True          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e9ea550-cebc-4382-984b-5cad93d718f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.629437</td>\n",
              "      <td>0.68559</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.646967</td>\n",
              "      <td>0.079037</td>\n",
              "      <td>28.068850</td>\n",
              "      <td>0.646967</td>\n",
              "      <td>0.079037</td>\n",
              "      <td>28.068850</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.629437</td>\n",
              "      <td>0.68559</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.650326</td>\n",
              "      <td>0.083040</td>\n",
              "      <td>28.077852</td>\n",
              "      <td>0.003359</td>\n",
              "      <td>0.004002</td>\n",
              "      <td>0.009001</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e9ea550-cebc-4382-984b-5cad93d718f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e9ea550-cebc-4382-984b-5cad93d718f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e9ea550-cebc-4382-984b-5cad93d718f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86a34c25-d2f7-45c5-9597-d7023de034c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86a34c25-d2f7-45c5-9597-d7023de034c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86a34c25-d2f7-45c5-9597-d7023de034c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"WeightedEnsemble_L2\",\n          \"LightGBM_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.6294365847604865,\n        \"max\": 0.6294365847604865,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6294365847604865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.685589519650655,\n        \"max\": 0.685589519650655,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.685589519650655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"f1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002375227794679944,\n        \"min\": 0.6469666957855225,\n        \"max\": 0.6503257751464844,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6503257751464844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0028300765838095124,\n        \"min\": 0.07903718948364258,\n        \"max\": 0.08303952217102051,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08303952217102051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006364848474721173,\n        \"min\": 28.06885027885437,\n        \"max\": 28.07785153388977,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          28.07785153388977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4550993099971171,\n        \"min\": 0.003359079360961914,\n        \"max\": 0.6469666957855225,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.003359079360961914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053057656066000235,\n        \"min\": 0.00400233268737793,\n        \"max\": 0.07903718948364258,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00400233268737793\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.84130952381312,\n        \"min\": 0.00900125503540039,\n        \"max\": 28.06885027885437,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00900125503540039\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Decision Threshold Calibration\n",
        "# We're adjusting how confident our model needs to be before making a prediction, to balance between different types of errors.\n",
        "# This is like setting the sensitivity of a smoke alarm - too sensitive and it goes off unnecessarily, not sensitive enough and it might miss real fires.\n",
        "\n",
        "print(f'Prior to calibration (predictor.decision_threshold={predictor.decision_threshold}):')\n",
        "scores = predictor.evaluate(test_data)\n",
        "\n",
        "calibrated_decision_threshold = predictor.calibrate_decision_threshold()\n",
        "predictor.set_decision_threshold(calibrated_decision_threshold)\n",
        "\n",
        "print(f'After calibration (predictor.decision_threshold={predictor.decision_threshold}):')\n",
        "scores_calibrated = predictor.evaluate(test_data)\n",
        "\n",
        "for metric_name in scores:\n",
        "    metric_score = scores[metric_name]\n",
        "    metric_score_calibrated = scores_calibrated[metric_name]\n",
        "    decision_threshold = predictor.decision_threshold\n",
        "    print(f'decision_threshold={decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n",
        "          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n",
        "          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n",
        "          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')\n",
        "\n",
        "predictor.set_decision_threshold(0.5)\n",
        "for metric_name in ['f1', 'balanced_accuracy', 'mcc']:\n",
        "    metric_score = predictor.evaluate(test_data, silent=True)[metric_name]\n",
        "    calibrated_decision_threshold = predictor.calibrate_decision_threshold(metric=metric_name, verbose=False)\n",
        "    metric_score_calibrated = predictor.evaluate(\n",
        "        test_data, decision_threshold=calibrated_decision_threshold, silent=True\n",
        "    )[metric_name]\n",
        "    print(f'decision_threshold={calibrated_decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n",
        "          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n",
        "          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n",
        "          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9VAGKQp8sNM",
        "outputId": "3b403912-42b0-4d39-959c-8cb48e9d7d77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior to calibration (predictor.decision_threshold=0.5):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calibrating decision threshold to optimize metric f1 | Checking 51 thresholds...\n",
            "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
            "\tBase Threshold: 0.500\t| val: 0.6856\n",
            "\tBest Threshold: 0.500\t| val: 0.6856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After calibration (predictor.decision_threshold=0.5):\n",
            "decision_threshold=0.500\t| metric=\"f1\"\n",
            "\ttest_score uncalibrated: 0.6294\n",
            "\ttest_score   calibrated: 0.6294\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.500\t| metric=\"accuracy\"\n",
            "\ttest_score uncalibrated: 0.8472\n",
            "\ttest_score   calibrated: 0.8472\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.500\t| metric=\"balanced_accuracy\"\n",
            "\ttest_score uncalibrated: 0.7438\n",
            "\ttest_score   calibrated: 0.7438\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.500\t| metric=\"mcc\"\n",
            "\ttest_score uncalibrated: 0.5457\n",
            "\ttest_score   calibrated: 0.5457\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.500\t| metric=\"roc_auc\"\n",
            "\ttest_score uncalibrated: 0.8990\n",
            "\ttest_score   calibrated: 0.8990\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.500\t| metric=\"precision\"\n",
            "\ttest_score uncalibrated: 0.7411\n",
            "\ttest_score   calibrated: 0.7411\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.500\t| metric=\"recall\"\n",
            "\ttest_score uncalibrated: 0.5470\n",
            "\ttest_score   calibrated: 0.5470\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.500\t| metric=\"f1\"\n",
            "\ttest_score uncalibrated: 0.6294\n",
            "\ttest_score   calibrated: 0.6294\n",
            "\ttest_score        delta: 0.0000\n",
            "decision_threshold=0.250\t| metric=\"balanced_accuracy\"\n",
            "\ttest_score uncalibrated: 0.7438\n",
            "\ttest_score   calibrated: 0.8120\n",
            "\ttest_score        delta: 0.0682\n",
            "decision_threshold=0.500\t| metric=\"mcc\"\n",
            "\ttest_score uncalibrated: 0.5457\n",
            "\ttest_score   calibrated: 0.5457\n",
            "\ttest_score        delta: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prediction Options\n",
        "# We're exploring different ways to use our trained model to make predictions about people's occupations.\n",
        "# This is like learning different techniques to use our camera, like taking single shots, burst mode, or videos, depending on what we're trying to capture.\n",
        "\n",
        "predictor = TabularPredictor.load(save_path)\n",
        "print(predictor.features())\n",
        "\n",
        "datapoint = test_data_nolabel.iloc[[0]]\n",
        "print(datapoint)\n",
        "predictor.predict(datapoint)\n",
        "\n",
        "predictor.predict_proba(datapoint)\n",
        "\n",
        "print(predictor.model_best)\n",
        "\n",
        "predictor.leaderboard(test_data)\n",
        "predictor.leaderboard(extra_info=True)\n",
        "predictor.leaderboard(test_data, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'])\n",
        "\n",
        "i = 0\n",
        "model_to_use = predictor.model_names()[i]\n",
        "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
        "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))\n",
        "\n",
        "all_models = predictor.model_names()\n",
        "model_to_use = all_models[i]\n",
        "specific_model = predictor._trainer.load_model(model_to_use)\n",
        "\n",
        "model_info = specific_model.get_info()\n",
        "predictor_information = predictor.info()\n",
        "\n",
        "y_pred_proba = predictor.predict_proba(test_data_nolabel)\n",
        "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)\n",
        "\n",
        "perf = predictor.evaluate(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl_PQuBs8vX2",
        "outputId": "6e1c63a1-5f6d-42a9-a3c3-6e47e53b20cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
            "   age workclass  fnlwgt education  education-num       marital-status  \\\n",
            "0   31   Private  169085      11th              7   Married-civ-spouse   \n",
            "\n",
            "  occupation relationship    race      sex  capital-gain  capital-loss  \\\n",
            "0      Sales         Wife   White   Female             0             0   \n",
            "\n",
            "   hours-per-week  native-country  \n",
            "0              20   United-States  \n",
            "WeightedEnsemble_L2\n",
            "Prediction from LightGBM_BAG_L1 model:  <=50K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Interpretability\n",
        "# We're trying to understand which characteristics are most important in predicting someone's occupation.\n",
        "# This is like figuring out which ingredients in a recipe contribute most to its taste.\n",
        "\n",
        "predictor.feature_importance(test_data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2yM258pY80UT",
        "outputId": "84de63f2-b896-4c16-fc7a-3934d921665b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 14 features using 5000 rows with 5 shuffle sets...\n",
            "\t20.89s\t= Expected runtime (4.18s per shuffle set)\n",
            "\t21.83s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                importance    stddev       p_value  n  p99_high   p99_low\n",
              "marital-status    0.117047  0.009311  4.765349e-06  5  0.136219  0.097875\n",
              "capital-gain      0.083102  0.004023  6.569424e-07  5  0.091385  0.074819\n",
              "education-num     0.071497  0.006756  9.453208e-06  5  0.085407  0.057587\n",
              "age               0.055806  0.009717  1.059856e-04  5  0.075814  0.035799\n",
              "occupation        0.055400  0.013509  3.925863e-04  5  0.083214  0.027585\n",
              "relationship      0.020842  0.006809  1.192225e-03  5  0.034861  0.006822\n",
              "hours-per-week    0.018326  0.006083  1.264850e-03  5  0.030850  0.005802\n",
              "capital-loss      0.003712  0.002108  8.495976e-03  5  0.008052 -0.000628\n",
              "education         0.000719  0.001339  1.480534e-01  5  0.003477 -0.002038\n",
              "native-country    0.000000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
              "race             -0.000400  0.000422  9.495569e-01  5  0.000468 -0.001268\n",
              "sex              -0.001557  0.001984  9.229631e-01  5  0.002527 -0.005642\n",
              "workclass        -0.002854  0.004633  8.797961e-01  5  0.006685 -0.012392\n",
              "fnlwgt           -0.007351  0.002614  9.983654e-01  5 -0.001968 -0.012734"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e3193ce-ee3b-4370-862b-c0e58a135ed0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>marital-status</th>\n",
              "      <td>0.117047</td>\n",
              "      <td>0.009311</td>\n",
              "      <td>4.765349e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.136219</td>\n",
              "      <td>0.097875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gain</th>\n",
              "      <td>0.083102</td>\n",
              "      <td>0.004023</td>\n",
              "      <td>6.569424e-07</td>\n",
              "      <td>5</td>\n",
              "      <td>0.091385</td>\n",
              "      <td>0.074819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education-num</th>\n",
              "      <td>0.071497</td>\n",
              "      <td>0.006756</td>\n",
              "      <td>9.453208e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.085407</td>\n",
              "      <td>0.057587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0.055806</td>\n",
              "      <td>0.009717</td>\n",
              "      <td>1.059856e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.075814</td>\n",
              "      <td>0.035799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>occupation</th>\n",
              "      <td>0.055400</td>\n",
              "      <td>0.013509</td>\n",
              "      <td>3.925863e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.083214</td>\n",
              "      <td>0.027585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relationship</th>\n",
              "      <td>0.020842</td>\n",
              "      <td>0.006809</td>\n",
              "      <td>1.192225e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.034861</td>\n",
              "      <td>0.006822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hours-per-week</th>\n",
              "      <td>0.018326</td>\n",
              "      <td>0.006083</td>\n",
              "      <td>1.264850e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.030850</td>\n",
              "      <td>0.005802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0.003712</td>\n",
              "      <td>0.002108</td>\n",
              "      <td>8.495976e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008052</td>\n",
              "      <td>-0.000628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education</th>\n",
              "      <td>0.000719</td>\n",
              "      <td>0.001339</td>\n",
              "      <td>1.480534e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.003477</td>\n",
              "      <td>-0.002038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>native-country</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>race</th>\n",
              "      <td>-0.000400</td>\n",
              "      <td>0.000422</td>\n",
              "      <td>9.495569e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>-0.001268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>-0.001557</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>9.229631e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.002527</td>\n",
              "      <td>-0.005642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>workclass</th>\n",
              "      <td>-0.002854</td>\n",
              "      <td>0.004633</td>\n",
              "      <td>8.797961e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.006685</td>\n",
              "      <td>-0.012392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fnlwgt</th>\n",
              "      <td>-0.007351</td>\n",
              "      <td>0.002614</td>\n",
              "      <td>9.983654e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.001968</td>\n",
              "      <td>-0.012734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e3193ce-ee3b-4370-862b-c0e58a135ed0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e3193ce-ee3b-4370-862b-c0e58a135ed0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e3193ce-ee3b-4370-862b-c0e58a135ed0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c6b2399-9479-471d-b389-218dcae3a516\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c6b2399-9479-471d-b389-218dcae3a516')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c6b2399-9479-471d-b389-218dcae3a516 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03970159695004696,\n        \"min\": -0.007350672688096638,\n        \"max\": 0.11704681093498373,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0,\n          -0.0015571526075094599,\n          0.11704681093498373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stddev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0039645970328823135,\n        \"min\": 0.0,\n        \"max\": 0.01350867073128891,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0,\n          0.0019837367412096733,\n          0.0093111182649275\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43029616473992677,\n        \"min\": 6.569424155026294e-07,\n        \"max\": 0.9983654022104883,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.5,\n          0.9229631401015995,\n          4.765348822782085e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04558396357269941,\n        \"min\": -0.001967696087655582,\n        \"max\": 0.13621853213580024,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.034753564291899706,\n        \"min\": -0.012733649288537693,\n        \"max\": 0.09787508973416723,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Accelerating Inference\n",
        "# We're speeding up our prediction process so we can handle large amounts of data more quickly.\n",
        "# This is like upgrading our camera to take photos faster, so we can capture rapid action shots.\n",
        "\n",
        "predictor.persist()\n",
        "\n",
        "num_test = 20\n",
        "preds = np.array(['']*num_test, dtype='object')\n",
        "for i in range(num_test):\n",
        "    datapoint = test_data_nolabel.iloc[[i]]\n",
        "    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n",
        "    preds[i] = pred_numpy[0]\n",
        "\n",
        "perf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\n",
        "print(\"Predictions: \", preds)\n",
        "\n",
        "predictor.unpersist()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxeW2D7q82h_",
        "outputId": "f04d5640-9d8d-4651-c416-fab1721125dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Persisting 2 models in memory. Models will require 0.02% of memory.\n",
            "Unpersisted 2 models: ['LightGBM_BAG_L1', 'WeightedEnsemble_L2']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:  [' <=50K' ' <=50K' ' >50K' ' <=50K' ' <=50K' ' >50K' ' >50K' ' >50K'\n",
            " ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K'\n",
            " ' <=50K' ' >50K' ' >50K' ' <=50K']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LightGBM_BAG_L1', 'WeightedEnsemble_L2']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inference Speed as a Fit Constraint\n",
        "# We're setting a speed limit for our predictions to ensure they're fast enough for real-time use.\n",
        "# This is like optimizing our photo-taking process to capture fleeting moments without blur.\n",
        "\n",
        "infer_limit = 0.00005\n",
        "infer_limit_batch_size = 10000\n",
        "predictor_infer_limit = TabularPredictor(label=label, eval_metric=metric).fit(\n",
        "    train_data=train_data,\n",
        "    time_limit=30,\n",
        "    infer_limit=infer_limit,\n",
        "    infer_limit_batch_size=infer_limit_batch_size,\n",
        ")\n",
        "\n",
        "predictor_infer_limit.persist()\n",
        "\n",
        "predictor_infer_limit.leaderboard()\n",
        "\n",
        "test_data_batch = test_data.sample(infer_limit_batch_size, replace=True, ignore_index=True)\n",
        "\n",
        "import time\n",
        "time_start = time.time()\n",
        "predictor_infer_limit.predict(test_data_batch)\n",
        "time_end = time.time()\n",
        "\n",
        "infer_time_per_row = (time_end - time_start) / len(test_data_batch)\n",
        "rows_per_second = 1 / infer_time_per_row\n",
        "infer_time_per_row_ratio = infer_time_per_row / infer_limit\n",
        "is_constraint_satisfied = infer_time_per_row_ratio <= 1\n",
        "\n",
        "print(f'Model is able to predict {round(rows_per_second, 1)} rows per second. (User-specified Throughput = {1 / infer_limit})')\n",
        "print(f'Model uses {round(infer_time_per_row_ratio * 100, 1)}% of infer_limit time per row.')\n",
        "print(f'Model satisfies inference constraint: {is_constraint_satisfied}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs-iQ_A784Q7",
        "outputId": "03826ef1-8dd6-4dc0-91a5-2152d35e54fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240916_044557\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.47 GB / 12.67 GB (82.6%)\n",
            "Disk Space Avail:   70.86 GB / 112.64 GB (62.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ... Time limit = 30s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240916_044557\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10717.42 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "\t2.421μs\t= Feature Preprocessing Time (1 row | 10000 batch size)\n",
            "\t\tFeature Preprocessing requires 4.84% of the overall inference constraint (0.05ms)\n",
            "\t\t0.048ms inference time budget remaining for models...\n",
            "Data preprocessing and feature engineering runtime = 0.3s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ... Training model for up to 29.7s of the 29.69s of remaining time.\n",
            "\t0.725\t = Validation score   (accuracy)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t3.936μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t3.936μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t3.936μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t3.936μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: KNeighborsDist ... Training model for up to 29.61s of the 29.61s of remaining time.\n",
            "\t0.71\t = Validation score   (accuracy)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t3.725μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t3.725μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t3.725μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t3.725μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: LightGBMXT ... Training model for up to 29.52s of the 29.52s of remaining time.\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t6.292μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t6.292μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t6.292μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t6.292μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: LightGBM ... Training model for up to 29.04s of the 29.03s of remaining time.\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.47s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t2.704μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t2.704μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t2.704μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t2.704μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: RandomForestGini ... Training model for up to 28.54s of the 28.53s of remaining time.\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "\t0.024ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.024ms\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.024ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.024ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: RandomForestEntr ... Training model for up to 27.36s of the 27.36s of remaining time.\n",
            "\t0.835\t = Validation score   (accuracy)\n",
            "\t0.99s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "\t0.026ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.026ms\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.026ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.026ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: CatBoost ... Training model for up to 26.25s of the 26.25s of remaining time.\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t4.29s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t1.929μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t1.929μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t1.929μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t1.929μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 21.94s of the 21.94s of remaining time.\n",
            "\t0.815\t = Validation score   (accuracy)\n",
            "\t1.0s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 20.81s of the 20.8s of remaining time.\n",
            "\t0.82\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.029ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 19.71s of the 19.7s of remaining time.\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t2.44s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t0.027ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.027ms\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.027ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.027ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: XGBoost ... Training model for up to 17.21s of the 17.21s of remaining time.\n",
            "\t0.845\t = Validation score   (accuracy)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t4.936μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t4.936μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t4.936μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t4.936μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 16.53s of the 16.52s of remaining time.\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t4.34s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t6.554μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t6.554μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t6.554μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t6.554μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Fitting model: LightGBMLarge ... Training model for up to 12.15s of the 12.14s of remaining time.\n",
            "\t0.815\t = Validation score   (accuracy)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t0.02ms\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t0.02ms\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.02ms\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t0.02ms\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "Removing 9/13 base models to satisfy inference constraint (constraint=0.045ms) ...\n",
            "\t0.185ms\t-> 0.182ms\t(KNeighborsDist)\n",
            "\t0.182ms\t-> 0.178ms\t(KNeighborsUnif)\n",
            "\t0.178ms\t-> 0.149ms\t(ExtraTreesGini)\n",
            "\t0.149ms\t-> 0.129ms\t(LightGBMLarge)\n",
            "\t0.129ms\t-> 0.1ms\t(ExtraTreesEntr)\n",
            "\t0.1ms\t-> 0.074ms\t(RandomForestEntr)\n",
            "\t0.074ms\t-> 0.071ms\t(LightGBM)\n",
            "\t0.071ms\t-> 0.047ms\t(RandomForestGini)\n",
            "\t0.047ms\t-> 0.02ms\t(NeuralNetFastAI)\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.7s of the 10.88s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost': 1.0}\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t0.053μs\t = Validation runtime (1 row | 10000 batch size | MARGINAL)\n",
            "\t1.981μs\t = Validation runtime (1 row | 10000 batch size)\n",
            "\t0.053μs\t = Validation runtime (1 row | 10000 batch size | REFIT | MARGINAL)\n",
            "\t1.981μs\t = Validation runtime (1 row | 10000 batch size | REFIT)\n",
            "AutoGluon training complete, total runtime = 19.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 37549.7 rows/s (200 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240916_044557\")\n",
            "Persisting 2 models in memory. Models will require 0.0% of memory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is able to predict 183223.0 rows per second. (User-specified Throughput = 20000.0)\n",
            "Model uses 10.9% of infer_limit time per row.\n",
            "Model satisfies inference constraint: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using Smaller Ensemble or Faster Model for Prediction\n",
        "# We're creating simplified versions of our model that can make predictions more quickly, trading some accuracy for speed.\n",
        "# This is like using a smaller, more portable camera that might not have all the features of a professional setup, but is quicker to use.\n",
        "\n",
        "additional_ensembles = predictor.fit_weighted_ensemble(expand_pareto_frontier=True)\n",
        "print(\"Alternative ensembles you can use for prediction:\", additional_ensembles)\n",
        "\n",
        "predictor.leaderboard(only_pareto_frontier=True)\n",
        "\n",
        "model_for_prediction = additional_ensembles[0]\n",
        "predictions = predictor.predict(test_data, model=model_for_prediction)\n",
        "predictor.delete_models(models_to_delete=additional_ensembles, dry_run=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4LZUlBe85di",
        "outputId": "e8b83822-006a-4757-9356-a1dc39177113"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting model: WeightedEnsemble_L2Best ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.6856\t = Validation score   (f1)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alternative ensembles you can use for prediction: ['WeightedEnsemble_L2Best']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deleting model WeightedEnsemble_L2Best. All files under agModels-predictClass/models/WeightedEnsemble_L2Best will be removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Collapsing Bagged Ensembles via refit_full\n",
        "# We're simplifying our complex model into a more streamlined version that's easier to use and understand.\n",
        "# This is like taking the best aspects of multiple camera setups and combining them into one easy-to-use camera.\n",
        "\n",
        "refit_model_map = predictor.refit_full()\n",
        "print(\"Name of each refit-full model corresponding to a previous bagged ensemble:\")\n",
        "print(refit_model_map)\n",
        "predictor.leaderboard(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "jP8z95Vy86bA",
        "outputId": "e76bbc84-8b77-48e2-8ebf-a9d8008dab87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t0.43s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
            "\t0.01s\t = Training   runtime\n",
            "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 0.52s ... Best model: \"WeightedEnsemble_L2_FULL\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name of each refit-full model corresponding to a previous bagged ensemble:\n",
            "{'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL', 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      model  score_test  score_val eval_metric  \\\n",
              "0      LightGBM_BAG_L1_FULL    0.634860        NaN          f1   \n",
              "1  WeightedEnsemble_L2_FULL    0.634860        NaN          f1   \n",
              "2           LightGBM_BAG_L1    0.629437    0.68559          f1   \n",
              "3       WeightedEnsemble_L2    0.629437    0.68559          f1   \n",
              "\n",
              "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0        0.104198            NaN   0.426320                 0.104198   \n",
              "1        0.109239            NaN   0.435322                 0.005042   \n",
              "2        0.972045       0.079037  28.068850                 0.972045   \n",
              "3        0.978032       0.083040  28.077852                 0.005986   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                     NaN           0.426320            1       True   \n",
              "1                     NaN           0.009001            2       True   \n",
              "2                0.079037          28.068850            1       True   \n",
              "3                0.004002           0.009001            2       True   \n",
              "\n",
              "   fit_order  \n",
              "0          3  \n",
              "1          4  \n",
              "2          1  \n",
              "3          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46c9a6c3-77f5-43d5-9f06-5be083affdcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1_FULL</td>\n",
              "      <td>0.634860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.104198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.426320</td>\n",
              "      <td>0.104198</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.426320</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2_FULL</td>\n",
              "      <td>0.634860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.109239</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.435322</td>\n",
              "      <td>0.005042</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009001</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.629437</td>\n",
              "      <td>0.68559</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.972045</td>\n",
              "      <td>0.079037</td>\n",
              "      <td>28.068850</td>\n",
              "      <td>0.972045</td>\n",
              "      <td>0.079037</td>\n",
              "      <td>28.068850</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.629437</td>\n",
              "      <td>0.68559</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.978032</td>\n",
              "      <td>0.083040</td>\n",
              "      <td>28.077852</td>\n",
              "      <td>0.005986</td>\n",
              "      <td>0.004002</td>\n",
              "      <td>0.009001</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46c9a6c3-77f5-43d5-9f06-5be083affdcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46c9a6c3-77f5-43d5-9f06-5be083affdcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46c9a6c3-77f5-43d5-9f06-5be083affdcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e98e17f2-2cc0-43af-8b33-cc2577a510db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e98e17f2-2cc0-43af-8b33-cc2577a510db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e98e17f2-2cc0-43af-8b33-cc2577a510db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"WeightedEnsemble_L2_FULL\",\n          \"WeightedEnsemble_L2\",\n          \"LightGBM_BAG_L1_FULL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031310635231461188,\n        \"min\": 0.6294365847604865,\n        \"max\": 0.6348597458643012,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6294365847604865,\n          0.6348597458643012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.685589519650655,\n        \"max\": 0.685589519650655,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.685589519650655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"f1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.501335167571802,\n        \"min\": 0.10419750213623047,\n        \"max\": 0.9780318737030029,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.10923910140991211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0028300765838095124,\n        \"min\": 0.07903718948364258,\n        \"max\": 0.08303952217102051,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08303952217102051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.959422962186986,\n        \"min\": 0.42632031440734863,\n        \"max\": 28.07785153388977,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.435321569442749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.46913080375906624,\n        \"min\": 0.005041599273681641,\n        \"max\": 0.9720454216003418,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.005041599273681641\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053057656066000235,\n        \"min\": 0.00400233268737793,\n        \"max\": 0.07903718948364258,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00400233268737793\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.961757374190071,\n        \"min\": 0.00900125503540039,\n        \"max\": 28.06885027885437,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.42632031440734863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model Distillation\n",
        "# We're creating a simplified version of our best model that's almost as good but much faster and easier to use.\n",
        "# This is like creating a point-and-shoot camera that captures photos almost as well as a professional setup, but is much simpler to operate.\n",
        "\n",
        "student_models = predictor.distill(time_limit=30)\n",
        "print(student_models)\n",
        "preds_student = predictor.predict(test_data_nolabel, model=student_models[0])\n",
        "print(f\"predictions from {student_models[0]}:\", list(preds_student)[:5])\n",
        "predictor.leaderboard(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0vJl3yYZ87Nr",
        "outputId": "e73f1260-68e1-4362-81b0-c7aff148028f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Distilling with teacher='WeightedEnsemble_L2_FULL', teacher_preds=soft, augment_method=spunge ...\n",
            "SPUNGE: Augmenting training data with 4000 synthetic samples for distillation...\n",
            "Distilling with each of these student models: ['LightGBM_DSTL', 'CatBoost_DSTL', 'RandomForestMSE_DSTL', 'NeuralNetTorch_DSTL']\n",
            "Fitting 4 L1 models ...\n",
            "Fitting model: LightGBM_DSTL ... Training model for up to 30.0s of the 30.0s of remaining time.\n",
            "\tWarning: Exception caused LightGBM_DSTL to fail during training... Skipping this model.\n",
            "\t\tpandas dtypes must be int, float or bool.\n",
            "Fields with bad pandas dtypes: workclass: object, education: object, marital-status: object, occupation: object, relationship: object, race: object, native-country: object\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
            "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 128, in train_lgb_model\n",
            "    return lgb.train(**train_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\", line 255, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 3433, in __init__\n",
            "    train_set.construct()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 2462, in construct\n",
            "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
            "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
            "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
            "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
            "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
            "ValueError: pandas dtypes must be int, float or bool.\n",
            "Fields with bad pandas dtypes: workclass: object, education: object, marital-status: object, occupation: object, relationship: object, race: object, native-country: object\n",
            "Fitting model: CatBoost_DSTL ... Training model for up to 29.42s of the 29.41s of remaining time.\n",
            "\tWarning: Exception caused CatBoost_DSTL to fail during training... Skipping this model.\n",
            "\t\tfeatures data: pandas.DataFrame column 'workclass' has dtype 'category' but is not in  cat_features list\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 125, in _fit\n",
            "    X_val = Pool(data=X_val, label=y_val, cat_features=cat_features, weight=sample_weight_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 855, in __init__\n",
            "    self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1491, in _init\n",
            "    self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n",
            "  File \"_catboost.pyx\", line 4339, in _catboost._PoolBase._init_pool\n",
            "  File \"_catboost.pyx\", line 4391, in _catboost._PoolBase._init_pool\n",
            "  File \"_catboost.pyx\", line 4200, in _catboost._PoolBase._init_features_order_layout_pool\n",
            "  File \"_catboost.pyx\", line 3083, in _catboost._set_features_order_data_pd_data_frame\n",
            "_catboost.CatBoostError: features data: pandas.DataFrame column 'workclass' has dtype 'category' but is not in  cat_features list\n",
            "Fitting model: RandomForestMSE_DSTL ... Training model for up to 29.1s of the 29.1s of remaining time.\n",
            "\tNote: model has different eval_metric than default.\n",
            "\t-0.1079\t = Validation score   (-mean_squared_error)\n",
            "\t7.85s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_DSTL ... Training model for up to 20.95s of the 20.95s of remaining time.\n",
            "\tWarning: Exception caused NeuralNetTorch_DSTL to fail during training... Skipping this model.\n",
            "\t\tFound array with 0 feature(s) (shape=(4800, 0)) while a minimum of 1 is required.\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
            "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 465, in _generate_datasets\n",
            "    train_dataset = self._process_train_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 538, in _process_train_data\n",
            "    df = self.processor.fit_transform(df)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 754, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 681, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 65, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 127, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 479, in fit_transform\n",
            "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 916, in fit_transform\n",
            "    return self.fit(X, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 727, in fit\n",
            "    self._fit(X, handle_unknown=\"ignore\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 193, in _fit\n",
            "    X_list, n_samples, n_features = self._check_X(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 164, in _check_X\n",
            "    X_temp = check_array(X, dtype=None, force_all_finite=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 976, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(4800, 0)) while a minimum of 1 is required.\n",
            "Repeating k-fold bagging: 2/5\n",
            "Repeating k-fold bagging: 3/5\n",
            "Repeating k-fold bagging: 4/5\n",
            "Repeating k-fold bagging: 5/5\n",
            "Completed 5/5 k-fold bagging repeats ...\n",
            "Distilling with each of these student models: ['WeightedEnsemble_L2_DSTL']\n",
            "Fitting model: WeightedEnsemble_L2_DSTL ... Training model for up to 30.0s of the 20.53s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_DSTL': 1.0}\n",
            "\tNote: model has different eval_metric than default.\n",
            "\t-0.1079\t = Validation score   (-mean_squared_error)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Distilled model leaderboard:\n",
            "                      model  score_val         eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      RandomForestMSE_DSTL   0.629213  mean_squared_error       0.075193  7.850623                0.075193           7.850623            1       True          5\n",
            "1  WeightedEnsemble_L2_DSTL   0.629213  mean_squared_error       0.075851  7.854496                0.000659           0.003872            2       True          6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RandomForestMSE_DSTL', 'WeightedEnsemble_L2_DSTL']\n",
            "predictions from RandomForestMSE_DSTL: [' <=50K', ' <=50K', ' >50K', ' <=50K', ' <=50K']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      model  score_test  score_val         eval_metric  \\\n",
              "0      LightGBM_BAG_L1_FULL    0.634860        NaN                  f1   \n",
              "1  WeightedEnsemble_L2_FULL    0.634860        NaN                  f1   \n",
              "2           LightGBM_BAG_L1    0.629437   0.685590                  f1   \n",
              "3       WeightedEnsemble_L2    0.629437   0.685590                  f1   \n",
              "4      RandomForestMSE_DSTL    0.607631   0.629213  mean_squared_error   \n",
              "5  WeightedEnsemble_L2_DSTL    0.607631   0.629213  mean_squared_error   \n",
              "\n",
              "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0        0.056756            NaN   0.426320                 0.056756   \n",
              "1        0.059070            NaN   0.435322                 0.002314   \n",
              "2        0.467674       0.079037  28.068850                 0.467674   \n",
              "3        0.470015       0.083040  28.077852                 0.002341   \n",
              "4        0.557352       0.075193   7.850623                 0.557352   \n",
              "5        0.561419       0.075851   7.854496                 0.004067   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                     NaN           0.426320            1       True   \n",
              "1                     NaN           0.009001            2       True   \n",
              "2                0.079037          28.068850            1       True   \n",
              "3                0.004002           0.009001            2       True   \n",
              "4                0.075193           7.850623            1       True   \n",
              "5                0.000659           0.003872            2       True   \n",
              "\n",
              "   fit_order  \n",
              "0          3  \n",
              "1          4  \n",
              "2          1  \n",
              "3          2  \n",
              "4          5  \n",
              "5          6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f8a7fad-bc37-46ad-b52f-fe24e05c9894\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LightGBM_BAG_L1_FULL</td>\n",
              "      <td>0.634860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.056756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.426320</td>\n",
              "      <td>0.056756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.426320</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2_FULL</td>\n",
              "      <td>0.634860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.059070</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.435322</td>\n",
              "      <td>0.002314</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009001</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.629437</td>\n",
              "      <td>0.685590</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.467674</td>\n",
              "      <td>0.079037</td>\n",
              "      <td>28.068850</td>\n",
              "      <td>0.467674</td>\n",
              "      <td>0.079037</td>\n",
              "      <td>28.068850</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.629437</td>\n",
              "      <td>0.685590</td>\n",
              "      <td>f1</td>\n",
              "      <td>0.470015</td>\n",
              "      <td>0.083040</td>\n",
              "      <td>28.077852</td>\n",
              "      <td>0.002341</td>\n",
              "      <td>0.004002</td>\n",
              "      <td>0.009001</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestMSE_DSTL</td>\n",
              "      <td>0.607631</td>\n",
              "      <td>0.629213</td>\n",
              "      <td>mean_squared_error</td>\n",
              "      <td>0.557352</td>\n",
              "      <td>0.075193</td>\n",
              "      <td>7.850623</td>\n",
              "      <td>0.557352</td>\n",
              "      <td>0.075193</td>\n",
              "      <td>7.850623</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>WeightedEnsemble_L2_DSTL</td>\n",
              "      <td>0.607631</td>\n",
              "      <td>0.629213</td>\n",
              "      <td>mean_squared_error</td>\n",
              "      <td>0.561419</td>\n",
              "      <td>0.075851</td>\n",
              "      <td>7.854496</td>\n",
              "      <td>0.004067</td>\n",
              "      <td>0.000659</td>\n",
              "      <td>0.003872</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f8a7fad-bc37-46ad-b52f-fe24e05c9894')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f8a7fad-bc37-46ad-b52f-fe24e05c9894 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f8a7fad-bc37-46ad-b52f-fe24e05c9894');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67390cf2-2938-4061-929b-487f9259e9f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67390cf2-2938-4061-929b-487f9259e9f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67390cf2-2938-4061-929b-487f9259e9f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"LightGBM_BAG_L1_FULL\",\n          \"WeightedEnsemble_L2_FULL\",\n          \"WeightedEnsemble_L2_DSTL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012890619887352676,\n        \"min\": 0.6076313894888409,\n        \"max\": 0.6348597458643012,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6348597458643012,\n          0.6294365847604865,\n          0.6076313894888409\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03254871985176773,\n        \"min\": 0.6292134831460675,\n        \"max\": 0.685589519650655,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6292134831460675,\n          0.685589519650655\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"mean_squared_error\",\n          \"f1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23904178138911175,\n        \"min\": 0.056756019592285156,\n        \"max\": 0.5614187717437744,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.056756019592285156,\n          0.05906963348388672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00358960407753856,\n        \"min\": 0.07519268989562988,\n        \"max\": 0.08303952217102051,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.08303952217102051,\n          0.0758514404296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.79620884110173,\n        \"min\": 0.42632031440734863,\n        \"max\": 28.07785153388977,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.42632031440734863,\n          0.435321569442749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25861504971560106,\n        \"min\": 0.0023136138916015625,\n        \"max\": 0.5573515892028809,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.056756019592285156,\n          0.0023136138916015625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04322686685914698,\n        \"min\": 0.0006587505340576172,\n        \"max\": 0.07903718948364258,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.00400233268737793,\n          0.0006587505340576172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.218199639248947,\n        \"min\": 0.0038721561431884766,\n        \"max\": 28.06885027885437,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.00900125503540039,\n          0.0038721561431884766\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Faster Presets or Hyperparameters\n",
        "# We're using pre-configured settings to quickly create models that are good enough for many purposes without requiring much setup time.\n",
        "# This is like using the automatic mode on a camera - it might not give you the absolute best picture possible, but it's quick and easy to use.\n",
        "\n",
        "presets = ['good_quality', 'optimize_for_deployment']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets=presets, time_limit=60)\n",
        "\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, hyperparameters='very_light', time_limit=60)\n",
        "\n",
        "excluded_model_types = ['KNN', 'NN_TORCH']\n",
        "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, excluded_model_types=excluded_model_types, time_limit=60)\n",
        "\n",
        "print(\"AutoGluon Tabular In-Depth Examples Completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBhVL_vH873X",
        "outputId": "3d7cc319-545e-4866-cf07-ffb8302f6d23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240916_044701\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.12 GB / 12.67 GB (79.8%)\n",
            "Disk Space Avail:   70.73 GB / 112.64 GB (62.8%)\n",
            "===================================================\n",
            "Presets specified: ['good_quality', 'optimize_for_deployment']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 15s of the 60s of remaining time (25%).\n",
            "\t\tContext path: \"AutogluonModels/ag-20240916_044701/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                      model  score_holdout  score_val eval_metric  pred_time_test pred_time_val  fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L1_FULL       0.866071   0.862613    accuracy        0.010535          None  3.094731                 0.010535                   None           3.094731            1       True          1\n",
            "1  WeightedEnsemble_L2_FULL       0.866071   0.862613    accuracy        0.012132          None  3.098649                 0.001598                   None           0.003917            2       True          2\n",
            "2  WeightedEnsemble_L3_FULL       0.866071   0.862613    accuracy        0.012522          None  3.097856                 0.001987                   None           0.003124            3       True          3\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t34s\t = DyStack   runtime |\t26s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 26s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240916_044701\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10136.51 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.23s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 17.26s of the 25.89s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t0.859\t = Validation score   (accuracy)\n",
            "\t22.85s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 25.9s of the -0.98s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.859\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 11 L2 models ...\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 25.9s of the -1.05s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.859\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 27.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1759.4 rows/s (125 batch size)\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t0.56s\t = Training   runtime\n",
            "Updated best model to \"LightGBMXT_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"LightGBMXT_BAG_L1_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 0.59s ... Best model: \"LightGBMXT_BAG_L1_FULL\"\n",
            "Deleting model LightGBMXT_BAG_L1. All files under AutogluonModels/ag-20240916_044701/models/LightGBMXT_BAG_L1 will be removed.\n",
            "Deleting model WeightedEnsemble_L2. All files under AutogluonModels/ag-20240916_044701/models/WeightedEnsemble_L2 will be removed.\n",
            "Deleting model WeightedEnsemble_L3. All files under AutogluonModels/ag-20240916_044701/models/WeightedEnsemble_L3 will be removed.\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240916_044701\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240916_044803\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.67 GB / 12.67 GB (76.3%)\n",
            "Disk Space Avail:   70.73 GB / 112.64 GB (62.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240916_044803\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9898.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.2s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.28s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "}\n",
            "Fitting 7 L1 models ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 59.72s of the 59.72s of remaining time.\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 59.09s of the 59.09s of remaining time.\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.85s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 58.18s of the 58.18s of remaining time.\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t4.75s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 53.41s of the 53.41s of remaining time.\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 52.21s of the 52.21s of remaining time.\n",
            "\t0.845\t = Validation score   (accuracy)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 51.85s of the 51.85s of remaining time.\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t3.11s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 48.71s of the 48.71s of remaining time.\n",
            "\t0.815\t = Validation score   (accuracy)\n",
            "\t0.9s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.72s of the 47.68s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost': 1.0}\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 12.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 33655.4 rows/s (200 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240916_044803\")\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240916_044815\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.15 GB / 12.67 GB (80.1%)\n",
            "Disk Space Avail:   70.72 GB / 112.64 GB (62.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
            "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
            "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
            "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
            "Beginning AutoGluon training ... Time limit = 60s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240916_044815\"\n",
            "Train Data Rows:    1000\n",
            "Train Data Columns: 14\n",
            "Label Column:       class\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [' >50K', ' <=50K']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10396.68 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
            "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
            "\t\t('int', ['bool']) : 1 | ['sex']\n",
            "\t0.1s = Fit runtime\n",
            "\t14 features in original data used to generate 14 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.19s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Excluded models: ['NN_TORCH', 'KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 10 L1 models ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 59.81s of the 59.81s of remaining time.\n",
            "\t0.85\t = Validation score   (accuracy)\n",
            "\t0.46s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 59.33s of the 59.33s of remaining time.\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.48s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ... Training model for up to 58.84s of the 58.83s of remaining time.\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ... Training model for up to 57.91s of the 57.91s of remaining time.\n",
            "\t0.835\t = Validation score   (accuracy)\n",
            "\t1.06s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 56.74s of the 56.73s of remaining time.\n",
            "\t0.86\t = Validation score   (accuracy)\n",
            "\t4.52s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 52.2s of the 52.2s of remaining time.\n",
            "\t0.815\t = Validation score   (accuracy)\n",
            "\t0.68s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 51.4s of the 51.4s of remaining time.\n",
            "\t0.82\t = Validation score   (accuracy)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 50.63s of the 50.63s of remaining time.\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.84\t = Validation score   (accuracy)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 49.47s of the 49.47s of remaining time.\n",
            "\t0.845\t = Validation score   (accuracy)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 49.1s of the 49.1s of remaining time.\n",
            "\t0.815\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.81s of the 48.07s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestEntr': 0.25, 'CatBoost': 0.25, 'LightGBMXT': 0.125, 'LightGBM': 0.125, 'RandomForestGini': 0.125, 'ExtraTreesEntr': 0.125}\n",
            "\t0.875\t = Validation score   (accuracy)\n",
            "\t0.11s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 12.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 793.8 rows/s (200 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240916_044815\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoGluon Tabular In-Depth Examples Completed\n"
          ]
        }
      ]
    }
  ]
}