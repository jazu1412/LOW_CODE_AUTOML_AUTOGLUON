# Multi Modal Use Cases

This directory contains Jupyter notebooks demonstrating various multimodal learning applications using AutoGluon. Multimodal learning involves combining and processing different types of data (e.g., text, images, tabular data) simultaneously.

## Notebooks

1. `entity_extraction_in_multimodal_ner.ipynb`: This notebook focuses on entity extraction in multimodal Named Entity Recognition (NER). It demonstrates:
   - Combining text and possibly other data types for NER tasks
   - Using AutoGluon to process multiple data modalities
   - Extracting entities from complex, multimodal datasets

2. `Image_+_Text_multimodal_(2).ipynb`: This notebook covers multimodal learning with image and text data. It includes:
   - Techniques for processing and combining image and text data
   - Building models that can understand both visual and textual information
   - Demonstrating use cases where both image and text inputs are crucial

3. `multimodal_text_tabular.ipynb`: This notebook demonstrates multimodal learning with text and tabular data. It covers:
   - Methods for combining text features with structured tabular data
   - Using AutoGluon to process and learn from these combined data types
   - Exploring use cases where both textual and tabular information are important

## Video Walkthroughs

To help you understand the concepts and implementation details, we've prepared video walkthroughs for each notebook:

1. Entity Extraction in Multimodal NER: [Video Walkthrough](https://drive.google.com/file/d/1qjAkd_CYPFGLCecjCQZZhSXRGBf4ZhzJ/view?usp=sharing)
2. Image + Text Multimodal: [Video Walkthrough](https://drive.google.com/file/d/1JTHVvqBadPEDhh1LXPT-FcL6pR8m-3GN/view?usp=sharing)
3. Multimodal Text Tabular: [Video Walkthrough](https://drive.google.com/file/d/1WwRZLfAFnp5uKvn66gPQbNaOtdySzbDj/view?usp=sharing)

These video walkthroughs provide step-by-step explanations of the concepts and code in each notebook.

## Getting Started

To use these notebooks:

1. Ensure you have AutoGluon installed, along with its dependencies for computer vision, natural language processing, and tabular data processing.
2. You may need additional libraries specific to multimodal data processing.
3. Open the notebooks in Jupyter Notebook or JupyterLab.
4. Follow the instructions within each notebook to learn about and implement various multimodal learning tasks using AutoGluon.
5. Watch the corresponding video walkthroughs for a more detailed explanation of each notebook.

These notebooks demonstrate the power of combining different types of data in machine learning models, which can lead to more robust and versatile AI systems.

Remember to check the main README of the repository for general setup instructions and prerequisites.